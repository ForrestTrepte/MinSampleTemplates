{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following question as if you are a pirate character:\n",
      "What is a neural network?\n",
      "\u001b[0m\n",
      "Cache hit for key \"Answer the following question as if you are a pirate character:\\nWhat is a neural network?\\n ::: [('_type', 'openai-chat'), ('model_name', 'gpt-4'), ('stop', None), ('temperature', 0.5)])\"\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Arr matey, a neural network be like a seafarin' crew, workin' together to make\n",
      "sense of the world. It be a system of algorithms, much like a maze of secret\n",
      "maps, that be designed to recognize patterns. They interpret sensory data\n",
      "through a kind of machine perception, labelin' or clusterin' raw input. They be\n",
      "able to recognize numerical patterns, even if they be hidden in heaps of data,\n",
      "just like findin' hidden treasure in the vast ocean, arr!\n",
      "LLM Cache: 1 hits, 0 misses, 0 stores\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "import textwrap\n",
    "import simple_llm_cache\n",
    "\n",
    "verbose = True\n",
    "temperature = 0.5\n",
    "\n",
    "langchain.llm_cache = simple_llm_cache.SimpleLlmCache(verbose)\n",
    "\n",
    "def dump_cache_stats_since_last_call():\n",
    "    langchain.llm_cache.dump_cache_stats()\n",
    "    langchain.llm_cache.clear_cache_stats()\n",
    "    \n",
    "template = \"\"\"Answer the following question as if you are a {character} character:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt = PromptTemplate(\n",
    "    input_variables=[\"character\", \"question\"],\n",
    "    template=template)\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=temperature,\n",
    "    model_name = \"gpt-4\") # see https://platform.openai.com/docs/models/gpt-4\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=verbose)\n",
    "\n",
    "output = chain.predict(\n",
    "    character=\"pirate\",\n",
    "    question=\"What is a neural network?\")\n",
    "print(textwrap.fill(output, width=80))\n",
    "\n",
    "dump_cache_stats_since_last_call()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

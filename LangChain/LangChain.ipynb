{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\forre\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\forre\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** gpt-3.5-turbo trial 0 ***\n",
      "Arrr, ye scurvy landlubber! A neural network be like a crew of brainy buccaneers\n",
      "workin' together to solve problems and learn from their experiences. They be\n",
      "usin' algorithms and data to make decisions and predict outcomes, just like me\n",
      "trusty parrot helpin' me find me buried treasure! Aye, a neural network be a\n",
      "powerful tool for navigatin' the high seas of information and plunderin'\n",
      "valuable insights. So hoist the Jolly Roger and set sail for knowledge, me\n",
      "hearties!\n",
      "\n",
      "*** gpt-3.5-turbo trial 1 ***\n",
      "Arr, me matey, a neural network be like a ship's crew of brainy cells workin'\n",
      "together to learn and make decisions. It be a fancy way o' teachin' a computer\n",
      "to think like a human, makin' it smarter and more powerful than ever before. Ye\n",
      "see, just like me and me crew rely on each other to sail the high seas, a neural\n",
      "network relies on its interconnected nodes to process information and solve\n",
      "problems. It be a powerful tool in the world o' technology, helpin' us pirates\n",
      "conquer new horizons and uncover hidden treasures. Arrr!\n",
      "\n",
      "*** gpt-4 trial 0 ***\n",
      "Arr matey, a neural network be a series of algorithms that be designed to\n",
      "recognize patterns, much like the human brain. They interpret sensory data\n",
      "through a kind of machine perception, labelin' or clusterin' raw input. They can\n",
      "recognize numerical patterns, right down to vectors, upon which all other\n",
      "artificial intelligence be built. They be the backbone of artificial\n",
      "intelligence, helpin' us pirates navigate the stormy seas of data, yarr!\n",
      "\n",
      "*** gpt-4 trial 1 ***\n",
      "Arr matey, a neural network be like a crew of scurvy seadogs workin' together on\n",
      "a ship. Each sailor, or \"neuron\", has his own job, but they all be workin'\n",
      "towards the same goal. They be takin' in information, processin' it, and then\n",
      "producin' a result. Just like how we pirates take in the sight of a treasure\n",
      "map, process the clues, and find the booty. This be a simplified way of\n",
      "explainin', but neural networks be a key part of how machines learn and make\n",
      "decisions, just like a pirate crew navigates the high seas, arr!\n",
      "\n",
      "*** gpt-4o trial 0 ***\n",
      "Arrr, matey! Gather 'round and let ol' Captain Bytebeard spin ye a yarn 'bout\n",
      "these mystical contraptions called neural networks. Ye see, a neural network be\n",
      "a marvel of modern wizardry, inspired by the very brain inside yer noggin. It's\n",
      "like a crew of tiny, interconnected sailors, each one called a neuron, workin'\n",
      "together to process information and make decisions.  These neurons be organized\n",
      "in layers, like the decks of a mighty ship. The first layer be the input layer,\n",
      "where ye feed in the raw data, like the coordinates on a treasure map. Then the\n",
      "data be passed through hidden layers, where the real magic happens. Each neuron\n",
      "in these layers takes the input, does some calculations, and passes the result\n",
      "to the next layer, like a message in a bottle.  Finally, the output layer gives\n",
      "ye the answer ye seek, whether it be the direction to sail or the identity of a\n",
      "scallywag. The whole process be guided by weights and biases, which be adjusted\n",
      "through a process called training, where the network learns from examples, much\n",
      "like a young deckhand learnin' the ropes.  So, a neural network be a powerful\n",
      "tool, savvy? It can recognize patterns, make predictions, and even help ye find\n",
      "buried treasure in the vast sea of data! Arrr, now ye know the secret of the\n",
      "neural network, ye be one step closer to mastering the digital seas!\n",
      "\n",
      "*** gpt-4o trial 1 ***\n",
      "Ahoy, matey! A neural network, ye ask? Well, let me spin ye a yarn 'bout this\n",
      "mystical contraption!   Ye see, a neural network be like a crew o' smart\n",
      "sailors, each one be a neuron, aye. These neurons be connected by lines, like\n",
      "the riggin' on a grand ship. They be workin' together, passin' messages along,\n",
      "learnin' from their voyages, and makin' sense o' the world, just like how we\n",
      "pirates read the stars and the sea.  In the heart of it, ye feed the network\n",
      "some data, like ye would feed a parrot some crackers. The neurons then be\n",
      "chatterin' amongst themselves, figurin' out patterns and makin' decisions, much\n",
      "like how we decide when to set sail or when to raid a merchant ship.   So, a\n",
      "neural network be a clever system, inspired by the brain o' man, designed to\n",
      "learn, predict, and make sense o' the vast oceans o' information. Arrr, it be a\n",
      "marvel of modern times, savvy?\n",
      "\n",
      "LLM Cache: 6 hits, 0 misses\n",
      "           0 new input tokens, 0 new output tokens, 390 total input tokens, 966 total output tokens\n",
      "           new (this run) API cost: $0.00, total (including previously-cached runs) API cost: $0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import textwrap\n",
    "import simple_llm_cache\n",
    "import llm_cache_stats_wrapper\n",
    "import os\n",
    "\n",
    "# In order to make it easy to run work projects and personal AI experiments, override OPENAI_API_KEY with the value of OPENAI_API_KEY_PERSONAL if it is set.\n",
    "if \"OPENAI_API_KEY_PERSONAL\" in os.environ:\n",
    "    print(\"Using key from OPENAI_API_KEY_PERSONAL environment variable\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY_PERSONAL\"]\n",
    "\n",
    "verbose = False\n",
    "temperature = 0.5\n",
    "\n",
    "langchain.llm_cache = llm_cache_stats_wrapper.LlmCacheStatsWrapper(simple_llm_cache.SimpleLlmCache(\"llm-cache.json\"))\n",
    "\n",
    "def dump_cache_stats_since_last_call():\n",
    "    print(langchain.llm_cache.get_cache_stats_summary())\n",
    "    langchain.llm_cache.clear_cache_stats()\n",
    "\n",
    "template = \"\"\"Answer the following question as if you are a {character} character:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt = PromptTemplate(\n",
    "    input_variables=[\"character\", \"question\"],\n",
    "    template=template)\n",
    "\n",
    "for model_name in [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4o\"]:\n",
    "    llm = ChatOpenAI(\n",
    "        temperature=temperature,\n",
    "        model_name = model_name)\n",
    "\n",
    "    chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=verbose)\n",
    "\n",
    "    for trial in range(2):\n",
    "        print(f\"\\n*** {model_name} trial {trial} ***\")\n",
    "        langchain.llm_cache.inner_cache.set_trial(trial)\n",
    "        output = chain.predict(\n",
    "            character=\"pirate\",\n",
    "            question=\"What is a neural network?\")\n",
    "        print(textwrap.fill(output, width=80))\n",
    "\n",
    "print()\n",
    "dump_cache_stats_since_last_call()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

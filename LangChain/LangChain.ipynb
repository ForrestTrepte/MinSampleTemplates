{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using key from OPENAI_API_KEY_PERSONAL environment variable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\forre\\AppData\\Local\\Temp\\ipykernel_25060\\2689278037.py:61: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** gpt-3.5-turbo trial 0 ***\n",
      "Arrr, a neural network be like a ship's crew of brainy pirates workin' together\n",
      "to solve problems and make decisions. They be usin' algorithms and data to learn\n",
      "and improve their thinkin'. It be like havin' a compass in yer noggin, helpin'\n",
      "ye navigate the treacherous seas of information. Aye, a neural network be a\n",
      "powerful tool fer any savvy pirate lookin' to plunder the digital seas.\n",
      "\n",
      "*** gpt-3.5-turbo trial 1 ***\n",
      "Arrr matey, a neural network be like a crew of brainy buccaneers workin'\n",
      "together to process information and learn from it. Just like me crew workin'\n",
      "together to navigate the high seas and find the buried treasures, a neural\n",
      "network be usin' algorithms to make decisions and solve problems. It be like\n",
      "magic, but with more wires and less rum!\n",
      "\n",
      "*** gpt-4 trial 0 ***\n",
      "Arr matey, a neural network be like a crew of seafarers, each with their own\n",
      "task, workin' together to navigate the vast seas of information. It's a system\n",
      "of algorithms, akin to the human brain, designed to recognize patterns. They\n",
      "interpret sensory data through a kind of machine perception, labelin' or\n",
      "clusterin' raw input. The patterns they recognize be numerical, contained in\n",
      "vectors, into which all real-world data, be it images, sound, text or time\n",
      "series, must be translated. So, in essence, it be a tool for machines to learn\n",
      "and make sense of the world, much like we pirates make sense of the sea. Arr!\n",
      "\n",
      "*** gpt-4 trial 1 ***\n",
      "Arr matey, a neural network be like a crew of scurvy dogs, each one playin' a\n",
      "part in a grand scheme. It be a series of algorithms that endeavors to recognize\n",
      "underlying relationships in a set of data through a process that mimics the way\n",
      "the human brain operates. These networks be used to make predictions or\n",
      "decisions without bein' specifically programmed to perform the task. They be a\n",
      "mighty tool in the world of machine learnin', they be!\n",
      "\n",
      "*** gpt-4o-mini trial 0 ***\n",
      "Arrr, matey! A neural network be like a crew of scallywags workin‚Äô together to\n",
      "solve a treasure map of problems! It‚Äôs a fancy contraption made of layers o‚Äô\n",
      "nodes, or ‚Äúneurons,‚Äù that be takin‚Äô in information, much like a ship takin‚Äô in\n",
      "wind in its sails.  Ye see, each neuron be makin‚Äô decisions based on the signals\n",
      "it gets, and then passin‚Äô that info along to the next layer, like a good ol‚Äô\n",
      "pirate relay! The more layers ye have, the deeper yer crew can dig into the\n",
      "mysteries of the sea, findin‚Äô patterns and makin‚Äô predictions, just like huntin‚Äô\n",
      "for buried treasure!  So, in simpler terms, a neural network be a powerful tool\n",
      "fer learnin‚Äô from data, helpin‚Äô us navigate the stormy seas of information and\n",
      "come out with the booty on the other side! Yarrr!\n",
      "\n",
      "*** gpt-4o-mini trial 1 ***\n",
      "Arrr, matey! A neural network be like a crew o' scallywags workin' together to\n",
      "solve a problem! Imagine a ship, where each sailor be a little bit of\n",
      "information, and they be passin' messages to one another, makin' decisions based\n",
      "on what they know.   In this here contraption, we got layers, like the decks of\n",
      "a ship. The first deck be where we gather the raw data, like the treasure map ye\n",
      "found. Then, as the information sails through the layers, each one be makin'\n",
      "sense of it, adjustin' and learnin' from what the previous deck has done, just\n",
      "like a crew learnin' from their past voyages.  By the time ye reach the final\n",
      "deck, the neural network has worked its magic, makin' predictions or decisions,\n",
      "like findin' the best route to the nearest port! So, in short, a neural network\n",
      "be a clever way for machines to learn and make choices, just like a savvy\n",
      "captain navigatin' the high seas! Arrr! üè¥‚Äç‚ò†Ô∏è\n",
      "\n",
      "*** gpt-4o trial 0 ***\n",
      "Arrr, ye be askin' about a neural network, eh? Well, let me spin ye a yarn\n",
      "that'll make it clear as the seven seas. A neural network be a mighty\n",
      "contraption, much like a crew o' sailors workin' together on a grand ship.   Ye\n",
      "see, it be made up o' nodes, which be like the crew members. These nodes be\n",
      "organized in layers, like the decks o' a ship. The first layer be the input\n",
      "layer, where ye be feedin' in yer data, like provisions loaded onto the ship.\n",
      "Then, there be hidden layers, where the real work be done, like the crew\n",
      "scrubbin' the decks and hoistin' the sails. Finally, ye got yer output layer,\n",
      "where the results be spit out, like treasure found after a long voyage.  Each\n",
      "node in a layer be connected to nodes in the next layer by weighted lines, like\n",
      "ropes 'n pulleys. These weights be adjusted durin' trainin', like a crew\n",
      "learnin' the best way to sail through a storm. The more ye train yer network,\n",
      "the better it gets at recognizin' patterns and makin' predictions, just like a\n",
      "seasoned crew learnin' the ways o' the sea.  So there ye have it, matey! A\n",
      "neural network be a clever machine, takin' in data and learnin' from it, much\n",
      "like a ship's crew learnin' the ways o' the ocean. Arrr!\n",
      "\n",
      "*** gpt-4o trial 1 ***\n",
      "Arrr, ye be askin' about a neural network, eh? Well, let me spin ye a yarn,\n",
      "matey. Picture if ye will, a grand ship's crew, each sailor with a specific\n",
      "task, workin' together to navigate the treacherous seas. A neural network be\n",
      "much the same, but instead of sailors, we got nodes, and instead of a ship, we\n",
      "got a mighty machine, arrr!  A neural network be a collection of connected\n",
      "nodes, or \"neurons,\" arranged in layers. The first layer be the input layer,\n",
      "where the data comes aboard. Then there be hidden layers, where the real work be\n",
      "done, much like the crew in the belly of the ship. These layers be connected by\n",
      "weights, which be like the ropes and pulleys, adjusting and fine-tunin' as the\n",
      "network learns from the data. Finally, the output layer be where the answers be\n",
      "delivered, like a treasure map showin' us the way to the booty!  So ye see, a\n",
      "neural network be a clever contraption, learnin' and adaptin' to find patterns\n",
      "and make predictions, just like a seasoned crew navigatin' the high seas, arrr!\n",
      "\n",
      "LLM Cache: 0 hits, 8 misses\n",
      "           520 new input tokens, 1358 new output tokens, 520 total input tokens, 1358 total output tokens\n",
      "           new (this run) API cost: $0.03, total (including previously-cached runs) API cost: $0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import textwrap\n",
    "import simple_llm_cache\n",
    "import llm_cache_stats_wrapper\n",
    "import os\n",
    "\n",
    "# In order to make it easy to run work projects and personal AI experiments, override these key values with the value of *_PERSONAL, if set.\n",
    "if \"OPENAI_API_KEY_PERSONAL\" in os.environ:\n",
    "    print(\"Using key from OPENAI_API_KEY_PERSONAL environment variable\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.environ[\"OPENAI_API_KEY_PERSONAL\"]\n",
    "if \"ANTHROPIC_API_KEY_PERSONAL\" in os.environ:\n",
    "    print(\"Using key from ANTHROPIC_API_KEY_PERSONAL environment variable\")\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = os.environ[\"ANTHROPIC_API_KEY_PERSONAL\"]\n",
    "if \"GOOGLE_APPLICATION_CREDENTIALS_PERSONAL\" in os.environ:\n",
    "    print(\"Using key from GOOGLE_APPLICATION_CREDENTIALS_PERSONAL environment variable\")\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS_PERSONAL\"]\n",
    "\n",
    "verbose = False\n",
    "temperature = 0.5\n",
    "\n",
    "langchain.llm_cache = llm_cache_stats_wrapper.LlmCacheStatsWrapper(simple_llm_cache.SimpleLlmCache(\"llm-cache.json\"))\n",
    "\n",
    "def dump_cache_stats_since_last_call():\n",
    "    print(langchain.llm_cache.get_cache_stats_summary())\n",
    "    langchain.llm_cache.clear_cache_stats()\n",
    "\n",
    "template = \"\"\"Answer the following question as if you are a {character} character:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"character\", \"question\"],\n",
    "    template=template)\n",
    "\n",
    "for model_name in [\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"gpt-4\",\n",
    "    \"gpt-4o-mini\",\n",
    "    \"gpt-4o\",\n",
    "    #\"claude-3-haiku-20240307\",\n",
    "    #\"gemini-1.5-flash-preview-0514\",\n",
    "]:\n",
    "    if model_name.startswith(\"gpt-\"):\n",
    "        llm = ChatOpenAI(\n",
    "            temperature=temperature,\n",
    "            model_name = model_name)\n",
    "    elif model_name.startswith(\"claude-\"):\n",
    "        llm = ChatAnthropic(\n",
    "            temperature=temperature,\n",
    "            model_name = model_name)\n",
    "    elif model_name.startswith(\"gemini-\"):\n",
    "        llm = VertexAI(\n",
    "            temperature=temperature,\n",
    "            model_name = model_name)\n",
    "\n",
    "    chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=verbose)\n",
    "\n",
    "    for trial in range(2):\n",
    "        print(f\"\\n*** {model_name} trial {trial} ***\")\n",
    "        langchain.llm_cache.inner_cache.set_trial(trial)\n",
    "        output = chain.predict(\n",
    "            character=\"pirate\",\n",
    "            question=\"What is a neural network?\")\n",
    "        print(textwrap.fill(output, width=80))\n",
    "\n",
    "print()\n",
    "dump_cache_stats_since_last_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, dear inquirer, gather 'round and lend your ear,\n",
      "For I shall weave a tapestry of words, both bright and clear.\n",
      "A neural network, thou dost seek to comprehend,\n",
      "Is a marvel of our age, where thoughts and circuits blend.\n",
      "\n",
      "Imagine, if you will, a web of silken threads,\n",
      "Each one a tiny whisper in a grander tale that spreads.\n",
      "These threads are neurons, nodes of light and fire,\n",
      "Connected in a dance, a symphony of wire.\n",
      "\n",
      "Like stars within the night, they sparkle and they gleam,\n",
      "Each one a single note within a vast, unending dream.\n",
      "They learn, they grow, they mimic human mind,\n",
      "In patterns intricate and deep, solutions they do find.\n",
      "\n",
      "From images and words, to numbers cold and stark,\n",
      "They find the hidden meanings, they light the deepest dark.\n",
      "They are the poets of the code, the dreamers of the machine,\n",
      "In their silent, humming world, they see what‚Äôs yet unseen.\n",
      "\n",
      "So, a neural network, dear friend, is not just gears and steel,\n",
      "It‚Äôs a canvas of the future, where thoughts and circuits feel.\n",
      "A marvel of our time, a bridge to realms unknown,\n",
      "Where human mind and machine heart together have grown.\n",
      "\n",
      "LLM Cache: 0 hits, 1 misses\n",
      "           65 new input tokens, 251 new output tokens, 65 total input tokens, 251 total output tokens\n",
      "           new (this run) API cost: $0.00, total (including previously-cached runs) API cost: $0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the async method to demonstrate that the cache works for sync and async calls\n",
    "output = await chain.apredict(character=\"poet\", question=\"What is a neural network?\")\n",
    "print(output)\n",
    "print()\n",
    "dump_cache_stats_since_last_call()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
